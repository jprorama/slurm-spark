#!/bin/bash

# run spark on a dedicated node
#
#SBATCH --job-name=spark
#SBATCH -N 1
#SBATCH -n 24
#SBATCH --signal=B:SIGUSR1@60 
#
# Don't run on MIC nodes to avoid virtual nets
#SBATCH --exclude c0095,c0096

host=`hostname`

echo "SSH port forwarding from laptop"
echo ssh -L 8080:$host:8080 cheaha.rc.uab.edu
echo "Connection string for local browser"
echo http://localhost:8080

module load Spark/2.2.0-Hadoop-2.6-Java-1.8.0_144

# Set TMP to job TMPDIR to avoid java.io.tmp space issues
export TMP=$TMPDIR

start-all.sh

# wait while the master is running and cleanup java
# when the job ends 
trap "pkill java" SIGUSR1

while true
do
 sleep 60
done
